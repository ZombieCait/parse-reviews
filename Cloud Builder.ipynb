{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import cx_Oracle\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals import joblib\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from PIL import Image\n",
    "from wordcloud import (WordCloud, get_single_color_func)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stemmer=SnowballStemmer(\"russian\")  \n",
    "\n",
    "stopwords=[u'и',u'в',u'во',u'что',u'он',u'на',u'я',u'с',u'со',u'как',u'а',u'то',u'все',u'она',u'так',u'его',u'но',u'да',u'ты',u'к',u'у',u'же',\n",
    "u'за',u'бы',u'по',u'только',u'ее',u'мне',u'было',u'вот',u'от',u'меня',u'еще', u'о',u'из',u'ему',u'теперь',u'когда',u'даже',u'ну',u'вдруг',\n",
    "u'ли',u'если',u'уже',u'или',u'ни',u'быть',u'был',u'него',u'до',u'вас',u'нибудь',u'опять',u'уж',u'вам',u'ведь',u'там',u'потом',u'себя',u'ничего',\n",
    "u'ей',u'может',u'они',u'тут',u'где',u'есть',u'надо',u'ней',u'для',u'мы',u'тебя',u'их',u'чем',u'была',u'сам',u'чтоб',u'без',u'будто',u'чего',u'раз',\n",
    "u'тоже',u'себе',u'под',u'будет',u'ж',u'тогда',u'кто',u'этот',u'того',u'потому',u'этого',u'какой',u'совсем',u'ним',u'здесь',u'этом',u'один',u'почти',u'мой',\n",
    "u'тем',u'чтобы', u'rur', u'rub', u'ru', u'руб', u'рублей', u'ндс', u'ooo', u'oao', u'без', u'ао', u'зао', u'г', u'ы', u'пао', u'гуп', u'ук',\n",
    "u'кпк', u'кх', u'бст', u'хк', u'ук', u'январь', u'февраль', u'март',u'апрель',u'май', u'июнь', u'июль', u'август', u'сентябрь', u'октябрь', u'ноябрь', u'декабрь',\n",
    "u'июл', u'феврал', u'распоряжение', u'облагается', u'n',  u'шт', u'период', u'г', u'eur', u'маы', u'апрел', u'июн', u'январ', u'иуне',\n",
    "u'иуле', u'дог', u'рублях', u'начисление', u'экз',  u'sd', u'возврат', u'взимание', u'ед', u'е', u'юр', u'а',u'б',u'в',u'г',u'д',u'е',u'ё',\n",
    "u'ж',u'з',u'и',u'к',u'л',u'м',u'н',u'о',u'п',u'р',u'с',u'т',u'у',u'ф',u'х',u'ц',u'ч',u'ш',u'щ',u'ъ',u'ы',u'ь',u'э',u'ю',u'я', u'р', u'б', u'н', u'нал', u'сч',\n",
    "u'запрос', u'ип', u'монеты', u'дс', u'бум', u'лоро', u'заявке', u'нальчик', 'a','b','v','g','d','e','e','zh','z','i','k','l','m','n','o','p','r','s','t','u','f','h',\n",
    "u'вал', u' подразд', u'приема', u'см', u'usd', u'sek', u'nok',  u'орому', u'орым', u'lc', u'usd', u'ов', u'vo', u'осб', u'сзб', u'visa', u'mastercard', u'тс',\n",
    "u'ммвб', u'фб', u'дату', u'инн', u'кпп', u'ко', u'пс', u'контр', u'кампания', u'бух', u'ген', u'дир', u'кампании', u'через', u'над', u'ксб', u'скб', u'над',\n",
    "u'списание', u'согл', u'распоряжению', u'свыше', u'виза', u'дог', u'файл', u'spe', u'spx', u'spdz', u'января',u'февраля', u'марта', u'апреля', u'мая', u'июня', u'июля', u'августа', u'сентября',\n",
    "u'октября', u'ноября', u'декабря', u'зао', u'ооо', u'оао', u'ао', u'без', u'пао', u'гуп', u'ук', u'кпк', u'кх', u'бст', u'хк']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_new_directory(name):\n",
    "    if not os.path.exists(name):\n",
    "            os.mkdir(name)\n",
    "            \n",
    "def delete_punctuation(s):\n",
    "    return ' '.join((re.sub(r'[№\"\\'-_/.:?!1234567890()%<>;,+#$&\\s+]', u' ', s)).split())\n",
    "\n",
    "def delete_stopwords(s):\n",
    "    return ' '.join([word for word in (re.sub(r'[()\\s+]', u' ', s)).split() if word not in stopwords])\n",
    "\n",
    "def get_campaign():\n",
    "    start_time=datetime.datetime.now()\n",
    "    con=cx_Oracle.connect('iskra/iskraurskb@iskra1_cskostat')\n",
    "    query=  \"select distinct pl_id_k_in_crm from( \"\\\n",
    "            \"select/*+ RESULT_CACHE*/ \"\\\n",
    "                \"case when pl_id_k_in_crm like '%ЦА%ЗП%ФОТ%' then \"\\\n",
    "                \"pl_id_k_in_crm || ' (ПИРС)' \"\\\n",
    "             \"else pl_id_k_in_crm end pl_id_k_in_crm, \"\\\n",
    "             \"pl_num_id, date_load, pl_status, pl_brand_com, pl_main_chanal \"\\\n",
    "             \"from atb_segmen_kp_pl)\"\n",
    "    print(query)\n",
    "    data=pd.read_sql(query, con=con)\n",
    "    print(\"End extracting data: \"+ str(datetime.datetime.now()-start_time))\n",
    "    return data\n",
    "\n",
    "def get_data(campaign_name):\n",
    "    start_time=datetime.datetime.now()\n",
    "    con=cx_Oracle.connect('iskra/iskraurskb@iskra1_cskostat')\n",
    "    query=\"select REGEXP_REPLACE(ltrim(REGEXP_REPLACE(TEXT, '[[:digit:]|[:punct:]]+', \\' \\'), \\' \\'), \\'( ){2,}\\', \\' \\') TEXT \"\\\n",
    "          \"from ( select  /*+ parallel(32)*/ lower(TO_CHAR(SUBSTR(tasks_comment,0, DBMS_LOB.getlength(tasks_comment)))) TEXT \"\\\n",
    "          \"from atb_segmen_tasks_kamp where status = 'Закрыта' and tasks_comment is not null and date_load='15.12.2017' and CAMPAIGN_ID_ZADACHA like '%\"+campaign_name+\"%')\"\n",
    "    print(query)\n",
    "    data=pd.read_sql(query, con=con)\n",
    "    print(\"End extracting data: \"+ str(datetime.datetime.now()-start_time))\n",
    "    return data\n",
    "\n",
    "def get_stat(data, filename):\n",
    "    df=pd.DataFrame()\n",
    "    for cls in list(data['class'].drop_duplicates()):\n",
    "        data_split=data[data['class']==cls]\n",
    "        df=df.append([[cls, data_split['class'].count()]])\n",
    "    df.columns=['class', 'count']\n",
    "    df.to_csv(filename+'_stat.csv', sep=';')\n",
    "    \n",
    "def cut_words_freq2(words_freq):\n",
    "    # для того, чтобы свернуть похожие ключевые слова\n",
    "    keys=list(words_freq.keys())\n",
    "    for word in keys:\n",
    "        if word in words_freq.keys():\n",
    "            stemmed_word=stemmer.stem(word) \n",
    "            similar_keys=[s for s in words_freq.keys() if stemmed_word in s]\n",
    "\n",
    "            similar_word_freq={}\n",
    "            for similar_key in similar_keys:\n",
    "                similar_word_freq[similar_key]=words_freq[similar_key]   \n",
    "            if len(similar_word_freq)!=0:\n",
    "                word_max=max(similar_word_freq, key=similar_word_freq.get)\n",
    "\n",
    "                for key in similar_keys:\n",
    "                    if word_max !=key:\n",
    "                        words_freq[word_max]+=words_freq[key]\n",
    "                        words_freq.pop(key)\n",
    "                        \n",
    "    return words_freq\n",
    "    \n",
    "def cut_words_freq(phrases):\n",
    "    keys=list(phrases.keys())\n",
    "    for phrase in keys:\n",
    "        if phrase in phrases.keys():\n",
    "            phrase=stemming(phrase.split())\n",
    "            print(phrase)\n",
    "\n",
    "            similar_phrases_freq={}\n",
    "            for word in phrase.split():\n",
    "                similar_keys=[s for s in phrases.keys() if word in s]\n",
    "                print(similar_keys)\n",
    "                for similar_key in similar_keys:\n",
    "                    print(phrases)\n",
    "                    if similar_key=='':\n",
    "                        continue\n",
    "                    similar_phrases_freq[similar_key]=phrases[similar_key]   \n",
    "\n",
    "                    if len(similar_phrases_freq)!=0:\n",
    "                        phrase_max=max(similar_phrases_freq, key=similar_phrases_freq.get)\n",
    "\n",
    "                        for i in range(len(similar_keys)):\n",
    "                             if word_max !=similar_keys[i]:\n",
    "                                print(similar_keys[i])\n",
    "                                phrases[word_max]+=phrases[similar_keys[i]]\n",
    "                                phrases.pop(similar_keys[i])\n",
    "                                similar_keys[i]=''\n",
    "    return phrases\n",
    "\n",
    "def get_cloud(count_words, data, filename, flag=0):\n",
    "    cloud_mask=np.array(Image.open(\"cloud form.png\"))\n",
    "    fig=plt.figure(figsize=(45,30))\n",
    "    wordcloud=WordCloud(collocations=False, background_color=\"white\", mask=cloud_mask, stopwords=stopwords, max_words=count_words)   \n",
    "    wordcloud.generate_from_frequencies(frequencies=data)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()      \n",
    "    fig.savefig(filename+'.png') \n",
    "    if flag==1:\n",
    "        return wordcloud\n",
    "       \n",
    "def collect(x):\n",
    "    for s in x.split(' '):\n",
    "        if (len(s)<4) & (s not in collection) & (s not in ['нет', 'не', 'др', 'уфк', 'физ']):\n",
    "            collection.append(s)\n",
    "            \n",
    "def get_colors():\n",
    "    colors=list(matplotlib.colors.cnames.keys())\n",
    "    colors=colors[::2] \n",
    "    len(colors)\n",
    "    return colors\n",
    "\n",
    "def get_color_big_class():\n",
    "    classes=pd.read_excel('Все кластеры.xlsx', encoding='cp1251')\n",
    "    hierach_classes={}\n",
    "    for cls, big_cls in zip(classes['Кластер - 2'], classes['Кластер - 1']):\n",
    "        hierach_classes[cls]=big_cls\n",
    "    neg_pos_color_big_cls={'Встреча': 'green',\n",
    "                           'Выполнено': 'green',\n",
    "                           'Неудачный контакт': 'grey',\n",
    "                           'Отказ': 'red',\n",
    "                           'Ошибка задачи': 'grey',\n",
    "                           'Перспектива': 'green',\n",
    "                           'Проблемный клиент': 'red',\n",
    "                           'Условия': 'red'}\n",
    "    \n",
    "    neg_pos_color_small_cls={}\n",
    "    for key in neg_pos_color_big_cls.keys():\n",
    "        if neg_pos_color_big_cls[key] in neg_pos_color_small_cls.keys():\n",
    "            neg_pos_color_small_cls[neg_pos_color_big_cls[key]]=neg_pos_color_small_cls[neg_pos_color_big_cls[key]]+(list(classes[classes['Кластер - 1']==key]['Кластер - 2'].values))\n",
    "        else:\n",
    "            neg_pos_color_small_cls[neg_pos_color_big_cls[key]]=list(classes[classes['Кластер - 1']==key]['Кластер - 2'].values)\n",
    "    print(neg_pos_color_small_cls)  \n",
    "    \n",
    "    small_cls={}\n",
    "    for key in neg_pos_color_small_cls.keys():\n",
    "        for values in neg_pos_color_small_cls[key]:\n",
    "            small_cls[values]=key\n",
    "    return small_cls\n",
    "\n",
    "def valid_date(string):\n",
    "    string=string.split(' ')\n",
    "    parsed_string=''\n",
    "    for token in string:\n",
    "            try:\n",
    "                 parsed_string+=' '+(re.sub(r'(\\d{2}).(\\d{2}).?(\\d{0,4})', r'дата\\время', token))\n",
    "            except ValueError:\n",
    "                 parsed_string+=' '+token\n",
    "    return parsed_string\n",
    "\n",
    "\n",
    "def stemming(words):\n",
    "    stemmed_words=[]\n",
    "    for word in words:\n",
    "        stemmed_words.append(stemmer.stem(word))\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "def preprocessing(data):\n",
    "    collection=[]\n",
    "    data=data.dropna()\n",
    "    data['TEXT'].apply(lambda x: collect(x))\n",
    "    stopwords=stopwords+collection\n",
    "    data['TEXT']=data['TEXT'].apply(lambda x: delete_stopwords(x))\n",
    "    data['TEXT']=data['TEXT'].apply(lambda x: delete_punctuation(valid_date(x.lower())).split())    \n",
    "    print(data['TEXT'])\n",
    "    data['TEXT']=data['TEXT'].apply(lambda x: stemming(x))\n",
    "    \n",
    "    data['TEXT']=data['TEXT'].apply(lambda x: x.replace('не ', 'не_').replace('нет ', 'нет_').replace('др ', 'др_'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class SimpleGroupedColorFunc(object):\n",
    "    \"\"\"Create a color function object which assigns EXACT colors\n",
    "       to certain words based on the color to words mapping\n",
    "       Parameters\n",
    "       ----------\n",
    "       color_to_words : dict(str -> list(str))\n",
    "         A dictionary that maps a color to the list of words.\n",
    "       default_color : str\n",
    "         Color that will be assigned to a word that's not a member\n",
    "         of any value from color_to_words.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, color_to_words, default_color):\n",
    "        self.word_to_color = {word: color\n",
    "                              for (color, words) in color_to_words.items()\n",
    "                              for word in words}\n",
    "\n",
    "        self.default_color = default_color\n",
    "\n",
    "    def __call__(self, word, **kwargs):\n",
    "        return self.word_to_color.get(word, self.default_color)\n",
    "\n",
    "\n",
    "class GroupedColorFunc(object):\n",
    "    \"\"\"Create a color function object which assigns DIFFERENT SHADES of\n",
    "       specified colors to certain words based on the color to words mapping.\n",
    "       Uses wordcloud.get_single_color_func\n",
    "       Parameters\n",
    "       ----------\n",
    "       color_to_words : dict(str -> list(str))\n",
    "         A dictionary that maps a color to the list of words.\n",
    "       default_color : str\n",
    "         Color that will be assigned to a word that's not a member\n",
    "         of any value from color_to_words.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, color_to_words, default_color):\n",
    "        self.color_func_to_words = [\n",
    "            (get_single_color_func(color), set(words))\n",
    "            for (color, words) in color_to_words.items()]\n",
    "\n",
    "        self.default_color_func = get_single_color_func(default_color)\n",
    "\n",
    "    def get_color_func(self, word):\n",
    "        \"\"\"Returns a single_color_func associated with the word\"\"\"\n",
    "        try:\n",
    "            color_func = next(\n",
    "                color_func for (color_func, words) in self.color_func_to_words\n",
    "                if word in words)\n",
    "        except StopIteration:\n",
    "            color_func = self.default_color_func\n",
    "\n",
    "        return color_func\n",
    "\n",
    "    def __call__(self, word, **kwargs):\n",
    "        return self.get_color_func(word)(word, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes=pd.read_excel('Все кластеры.xlsx', encoding='cp1251')\n",
    "hierach_classes={}\n",
    "for cls, big_cls in zip(classes['Кластер - 2'], classes['Кластер - 1']):\n",
    "    hierach_classes[cls]=big_cls\n",
    "hierach_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "digit_class=joblib.load('declasses_dict.pkl')\n",
    "classifier=joblib.load('clf_done.pkl')\n",
    "\n",
    "#Получение списка компаний\n",
    "# campaigns=get_campaign()\n",
    "# campaigns=pd.read_excel('count компаний продаж.xlsx', encoding='cp1251')\n",
    "# campaigns=campaigns['CAMPAIGN_ID_ZADACHA'].values[:10]\n",
    "# campaigns=campaigns.dropna()\n",
    "# print(campaigns.shape[0])\n",
    "# campaigns=campaigns['PL_ID_K_IN_CRM'].values\n",
    "campaigns=['ЦА-ПРОДММБ-0117' ]\n",
    "for campaign in campaigns:\n",
    "    collection=[]\n",
    "    create_new_directory(campaign)\n",
    "    data=get_data(campaign)\n",
    "    print(campaign +': '+str(data.shape[0]))\n",
    "    data=data.dropna()\n",
    "    data['TEXT'].apply(lambda x: collect(x))\n",
    "    stopwords=stopwords+collection\n",
    "    if 'нет' in stopwords:\n",
    "        break\n",
    "    data['TEXT']=data['TEXT'].apply(lambda x: delete_stopwords(x))\n",
    "    data['TEXT']=data['TEXT'].apply(lambda x: x.replace('не ', 'не_').replace('нет ', 'нет_').replace('др ', 'др_'))\n",
    "    data['class']= classifier.predict(data['TEXT'].values)\n",
    "    data['class']=data['class'].apply(lambda x: digit_class[x])\n",
    "    data=data[data['class']!='мусор']\n",
    "    data.to_csv(campaign+'\\\\'+campaign+'.csv', sep=';')\n",
    "    get_stat(data, campaign+'\\\\'+campaign)\n",
    "\n",
    "    #Отрисовка облаков\n",
    "      \n",
    "    group_words={}\n",
    "    for cls in list(data['class'].drop_duplicates()):\n",
    "        data_split=data[data['class']==cls]\n",
    "        \n",
    "        vectorizer=CountVectorizer(max_features=30, ngram_range=(3,3))\n",
    "        counts = vectorizer.fit_transform(data_split['TEXT']).toarray().sum(axis=0)                                               \n",
    "        words = vectorizer.get_feature_names()    \n",
    "        print(cls)\n",
    "        print(words)\n",
    "        \n",
    "        words_freq={}\n",
    "        for word, count in zip(words, counts):\n",
    "            words_freq[word]=count\n",
    "        words_freq=cut_words_freq(words_freq)            \n",
    "        group_words[cls]=words_freq\n",
    "       \n",
    "        create_new_directory(campaign+'\\\\clouds\\\\')\n",
    "        get_cloud(10, words_freq, campaign+'\\\\clouds\\\\'+cls.replace('\\\\', '.'))\n",
    "        \n",
    "    all_words={}\n",
    "    for lst in list(group_words.values()):\n",
    "        all_words.update(lst)\n",
    "\n",
    "    cloud=get_cloud(200, all_words, 'all', 1)\n",
    "\n",
    "    class_colors=get_color_big_class()\n",
    "    colored_words={}\n",
    "    keys=list(group_words.keys())\n",
    "    for key in keys:\n",
    "        if key=='мусор':\n",
    "            continue\n",
    "        if class_colors[key] in colored_words:\n",
    "            colored_words[class_colors[key]]= colored_words[class_colors[key]]+list(group_words[key])\n",
    "        else:\n",
    "            colored_words[class_colors[key]]=list(group_words[key])\n",
    "\n",
    "            default_color='grey'\n",
    "    grouped_color_func = GroupedColorFunc(colored_words, default_color)\n",
    "    cloud.recolor(color_func=grouped_color_func)\n",
    "    fig=plt.figure(figsize=(45,30))\n",
    "    plt.imshow(cloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(campaign+'\\\\clouds\\\\all_colored.png')   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaigns=['ЦА-ПРОДММБ-0117']\n",
    "for campaign in campaigns:\n",
    "    create_new_directory(campaign)\n",
    "    data=get_data(campaign)\n",
    "    data=data.dropna()\n",
    "    \n",
    "    #stopwords\n",
    "    collection=[]\n",
    "    data['TEXT'].apply(lambda x: collect(x))\n",
    "    stopwords=stopwords+collection\n",
    "    \n",
    "    \n",
    "    data['TEXT']=data['TEXT'].apply(lambda x: delete_stopwords(x))\n",
    "    data['TEXT']=data['TEXT'].apply(lambda x: delete_punctuation(valid_date(x.lower())).split())    \n",
    "    print(data['TEXT'])\n",
    "    data['TEXT_STEMMED']=data['TEXT'].apply(lambda x: stemming(x))\n",
    "    data['TEXT']=data['TEXT'].apply(lambda x: ' '.join(x))\n",
    "    print(campaign +': '+str(data.shape[0]))\n",
    "    data.to_csv('preprocessing_result.csv', sep=';', encoding='cp1251')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load\n",
    "digit_class=joblib.load('declasses_dict.pkl')\n",
    "classifier=joblib.load('clf_done.pkl')\n",
    "\n",
    "data['class']= classifier.predict(data['TEXT'].values)\n",
    "data['class']=data['class'].apply(lambda x: digit_class[x])\n",
    "data=data[data['class']!='мусор']\n",
    "data.to_csv(campaign+'\\\\'+campaign+'.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Отрисовка облаков\n",
    "      \n",
    "group_words={}\n",
    "for cls in list(data['class'].drop_duplicates()):\n",
    "    data_split=data[data['class']==cls]\n",
    "\n",
    "    vectorizer=CountVectorizer(max_features=10, ngram_range=(2,2))\n",
    "    counts = vectorizer.fit_transform(data_split['TEXT']).toarray().sum(axis=0)                                               \n",
    "    words = vectorizer.get_feature_names() \n",
    "    print(cls)\n",
    "    print(words)\n",
    "    \n",
    "    words_freq={}\n",
    "    for word, count in zip(words, counts):\n",
    "        words_freq[word]=count\n",
    "    words_freq=cut_words_freq(words_freq)            \n",
    "    group_words[cls]=words_freq\n",
    "    \n",
    "all_words={}\n",
    "for lst in list(group_words.values()):\n",
    "    all_words.update(lst)\n",
    "\n",
    "cloud=get_cloud(100, all_words, 'all', 1)\n",
    "\n",
    "class_colors=get_color_big_class()\n",
    "colored_words={}\n",
    "keys=list(group_words.keys())\n",
    "for key in keys:\n",
    "    if key=='мусор':\n",
    "        continue\n",
    "    if class_colors[key] in colored_words:\n",
    "        colored_words[class_colors[key]]= colored_words[class_colors[key]]+list(group_words[key])\n",
    "    else:\n",
    "        colored_words[class_colors[key]]=list(group_words[key])\n",
    "\n",
    "        default_color='grey'\n",
    "# grouped_color_func = GroupedColorFunc(colored_words, default_color)\n",
    "# cloud.recolor(color_func=grouped_color_func)\n",
    "# fig=plt.figure(figsize=(45,30))\n",
    "# plt.imshow(cloud, interpolation=\"bilinear\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# fig.savefig(campaign+'\\\\clouds\\\\all_colored.png')   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
